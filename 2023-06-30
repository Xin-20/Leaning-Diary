# Today's work  
[x] Generate the data for the new game  
background: virtual vtuber setup -> QA   
inno-gpt-35-turbo  
gpt-4-32k  
inno-gpt-4  
# Proposed work  
- [ ] Finetune baichuan  
hiyouga/LLaMA-Efficient-Tuning: Fine-tuning LLaMA with PEFT (PT+SFT+RLHF with QLoRA) (github.com)  https://github.com/hiyouga/LLaMA-Efficient-Tuning    
- [ ] Read PEFT Repo, typing, dataclasses library    
- [ ] Read finetune and inference code    
- [ ] Read achitecture source code      
- [ ] Langchain and documentsearch(local library)  
DocumentSearch/demo.py at main · yuanzhoulvpi2017/DocumentSearch (github.com)  https://github.com/yuanzhoulvpi2017/DocumentSearch/blob/main/demo.py  
imClumsyPanda/langchain-ChatGLM: langchain-ChatGLM, local knowledge based ChatGLM with langchain ｜ 基于本地知识库的 ChatGLM 问答 (github.com)  https://github.com/imClumsyPanda/langchain-ChatGLM  
- [ ] Write my own lora training file(possible for chatglm2)  
- [ ] Understand all generate and finetune souce code and try to write fine tune file with peft  
# After work 30 mins
- [ ] Learn more generative AI from Hung-yi Lee course  
- [ ] Complete my Python base (100 days with Python)  
jarodHAN/Python-100-Days-master: python100天学习资料 (github.com)  https://github.com/jarodHAN/Python-100-Days-master  
- [ ] Create a data scientist resume  
- [ ] apply for fall job  
