# Today's work
- [x] Design a small question set to test model  
- [x] test vicuna-13b(terrible performance)  
python finetune.py --base_model 'vicuna-13b-v1.3/' --data_path 'data/up-2023-7-7-doc-vicuna.json' --output_dir './finetune-vicuna-up-1' --num_epochs 30 --learning_rate 1e-4 --cutoff_len 1024 --val_set_size 0 --lora_target_modules '[q_proj,v_proj,k_proj,o_proj]' --add_eos_token True  
python generate.py     --load_8bit     --base_model 'vicuna-13b-v1.3/'     --lora_weights 'finetune-vicuna-up-1/  
- [x] reconstruct data input(edit on instruction, more background, and correct some reponse for coding part) and then retrain the Ziya model  
python finetune.py --base_model 'Ziya-LLaMA-13B/' --data_path 'data/up-2023-7-10-doc1-InsChange.json' --output_dir './finetune-Ziya-up-5' --num_epochs 25 --learning_rate 1e-4 --cutoff_len 1024 --val_set_size 0 --lora_target_modules '[q_proj,v_proj,k_proj,o_proj]' --add_eos_token True  
- [x] Background setup for character, generate conversation corpus.  
- [ ] RLHF tuning  
hiyouga/LLaMA-Efficient-Tuning: Easy-to-use fine-tuning framework using PEFT (PT+SFT+RLHF with QLoRA) (github.com)  https://github.com/hiyouga/LLaMA-Efficient-Tuning  
# Questions
# Gossip
# Proposed work
- [ ] Read PEFT Repo, typing, dataclasses library
- [ ] Understand all generate and finetune souce code and try to write fine tune file with peft
- [ ] Langchain and documentsearch(local library)
DocumentSearch/demo.py at main · yuanzhoulvpi2017/DocumentSearch (github.com)  https://github.com/yuanzhoulvpi2017/DocumentSearch/blob/main/demo.py  
imClumsyPanda/langchain-ChatGLM: langchain-ChatGLM, local knowledge based ChatGLM with langchain ｜ 基于本地知识库的 ChatGLM 问答 (github.com)  https://github.com/imClumsyPanda/langchain-ChatGLM  
# After work 30 mins
- [ ] Create a data scientist resume  
- [ ] apply for fall job  

